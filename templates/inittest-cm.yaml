apiVersion: v1
kind: ConfigMap
metadata:
  name: inittestsh
  namespace: {{ .Release.Namespace }}
data:
  inittestsh-config: |-
    {{- $app_namespace_bak := .Values.global.app_namespace_bak }}
    {{- $chartName := .Chart.Name }}
    {{- $namespace := .Release.Namespace }}
    {{- $nodeReplicaCount := .Values.ReplicaCount | default 3 }}
    #!/bin/bash
    source /etc/profile
    echo `date` >> /user/b.txt
    host_num=`echo $HOSTNAME | awk -F- '{print $NF}'`
    mkdir -p /user/data/zookeeper
    echo $host_num > /user/data/zookeeper/myid;

    {{ range $nodecount, $e := until ($nodeReplicaCount|int) }}
      {{- if eq $nodecount 0 }}
    host_dns=( "{{ $chartName }}-ss-{{ $nodecount }}.ha-svc.{{ $namespace }}.svc.cluster.local"
      {{- else if eq $nodecount (sub $nodeReplicaCount 1)}}
        {{- " " }}"{{ $chartName }}-ss-{{ $nodecount }}.ha-svc.{{ $namespace }}.svc.cluster.local" )
      {{- else}}
        {{- " " }}"{{ $chartName }}-ss-{{ $nodecount }}.ha-svc.{{ $namespace }}.svc.cluster.local"
      {{- end }}
    {{- end }}

    {{ range $nodecount, $e := until ($nodeReplicaCount|int) }}
      host_dns_{{ $nodecount }}="{{ $chartName }}-ss-{{ $nodecount }}.ha-svc.{{ $namespace }}.svc.cluster.local"
    {{- end }}
    
    until [ {{ range $key, $val := until ($nodeReplicaCount|int) }}`ping -c 1 {{ $chartName }}-ss-{{ $key }}.ha-svc.{{ $namespace }}.svc.cluster.local | grep ', 0% packet loss,' | wc -l` = 1 {{ if eq $key (sub $nodeReplicaCount 1) }}{{- else }} -a {{ end }}  {{ end }}]
    do
      sleep 3
      echo "等待DNS服务"
    done
    for i in "${host_dns[@]}"
    do
      echo $i
      ssh root@$i "source /etc/profile && zkServer.sh start"
    done

    if [ $host_num -eq 0 ];then
      hadoop-daemons.sh start journalnode
      sh /user/nodeinfo/start.sh zkfc
      sh /user/nodeinfo/start.sh nnfc $host_dns_2

      hadoop-daemon.sh start zkfc
      hadoop-daemon.sh start namenode
      hadoop-daemon.sh start datanode
  
      # start-dfs.sh



      # start-yarn.sh
      yarn-daemon.sh start resourcemanager
      yarn-daemon.sh start nodemanager


      # start-hbase.sh
      hbase-daemon.sh start master
      hbase-daemon.sh start regionserver

      sh /user/nodeinfo/start.sh spark
    
    elif [ $host_num -eq 1 ];then
      hadoop-daemon.sh start journalnode
      
      
      
      
      sleep 30
      hadoop-daemon.sh start datanode

      yarn-daemon.sh start resourcemanager
      yarn-daemon.sh start nodemanager

      hbase-daemon.sh start regionserver
      
      sh /user/nodeinfo/start.sh oozie
      
    elif [ $host_num -eq 2 ];then
      until [ -d /user/data/hadoop/hdfs/name ]
      do
        sleep 2
      done

      hadoop-daemon.sh start journalnode
      hadoop-daemon.sh start zkfc
      hadoop-daemon.sh start namenode
      hadoop-daemon.sh start datanode

      yarn-daemon.sh start nodemanager

      mr-jobhistory-daemon.sh start historyserver

      
      sh /user/nodeinfo/start.sh flink
      historyserver.sh start
      start-history-server.sh

      hbase-daemon.sh start master
      hbase-daemon.sh start regionserver

    else
      echo 'other'
    fi
